{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T23:05:27.114182Z",
     "start_time": "2025-01-11T23:05:25.510487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from operator import truediv\n",
    "\n",
    "import numpy as np\n",
    "import code_for_hw02_downloadable as helper"
   ],
   "id": "78f2ad61744d9e52",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T14:16:04.907573Z",
     "start_time": "2025-01-12T14:16:04.893521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def perceptron(data, labels, params={}, hook=None):\n",
    "    # if T not in params, default to 100\n",
    "    T = params.get('T', 100)\n",
    "\n",
    "    # Your implementation here\n",
    "    d, n = data.shape\n",
    "    th = np.zeros((d, 1))\n",
    "    th0 = np.zeros((1, 1))\n",
    "    num_mistakes = 0\n",
    "    for t in range(T):\n",
    "        for i in range(n):\n",
    "            x = data[:, i:i + 1]\n",
    "            y = labels[:, i:i + 1]\n",
    "            if y * (th.T @ x + th0) <= 0:\n",
    "                num_mistakes +=1\n",
    "                th += y * x\n",
    "                th0 += y\n",
    "                print(th,th0)\n",
    "            if hook:\n",
    "                hook((th, th0))\n",
    "    print(num_mistakes)\n",
    "    return th, th0\n",
    "\n",
    "# print(perceptron(np.array([[2,3,4,5]]), np.array([[1,1,-1,-1]])))\n",
    "# data = np.zeros((6, 4))\n",
    "# data[1][0] = 1\n",
    "# data[2][1] = 1\n",
    "# data[3][2] = 1\n",
    "# data[4][3] = 1\n",
    "# print(data)\n",
    "# labels = np.array([[1,1,-1,-1]])\n",
    "data = np.identity(6)\n",
    "print(data)\n",
    "labels = np.array([[1,1,-1,-1,1,1]])\n",
    "print(perceptron(data, labels))\n",
    "# helper.test_perceptron(perceptron)\n",
    "\n"
   ],
   "id": "1488ea35da080d35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [[1.]]\n",
      "[[ 1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]] [[0.]]\n",
      "[[ 1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 0.]] [[-1.]]\n",
      "[[ 1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 0.]] [[0.]]\n",
      "[[ 1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]] [[1.]]\n",
      "[[ 1.]\n",
      " [ 0.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]] [[0.]]\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]] [[1.]]\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [ 1.]\n",
      " [ 1.]] [[0.]]\n",
      "8\n",
      "(array([[ 1.],\n",
      "       [ 1.],\n",
      "       [-2.],\n",
      "       [-2.],\n",
      "       [ 1.],\n",
      "       [ 1.]]), array([[0.]]))\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T23:05:27.745538Z",
     "start_time": "2025-01-11T23:05:27.729323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def averaged_perceptron(data, labels, params={}, hook=None):\n",
    "    # if T not in params, default to 100\n",
    "    T = params.get('T', 100)\n",
    "\n",
    "    # Your implementation here\n",
    "    d, n = data.shape\n",
    "\n",
    "    th = np.zeros((d, 1))\n",
    "    th0 = np.zeros((1, 1))\n",
    "\n",
    "    ths = np.zeros((d,1))\n",
    "    th0s = np.zeros((1,1))\n",
    "    # ths = np.zeros((d, 0))\n",
    "    # th0s = np.zeros((1, 0))\n",
    "\n",
    "    for t in range(T):\n",
    "        for i in range(n):\n",
    "            x = data[:, i:i + 1]\n",
    "            y = labels[:, i:i + 1]\n",
    "            if y * (th.T @ x + th0) <= 0:\n",
    "                th += y * x\n",
    "                th0 += y\n",
    "\n",
    "            ths += th\n",
    "            th0s += th0\n",
    "            # ths = np.concatenate((ths, th), axis=1)\n",
    "            # th0s = np.concatenate((th0s, th0), axis=1)\n",
    "            if hook:\n",
    "                hook((th, th0))\n",
    "    return ths/(n*T), th0s/(n*T)\n",
    "    # return np.mean(ths, axis=1, keepdims=True), np.mean(th0s, axis=1, keepdims=True)\n",
    "\n",
    "helper.test_averaged_perceptron(averaged_perceptron)\n"
   ],
   "id": "643d3ec2a8dc5482",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Averaged Perceptron 0-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Averaged Perceptron 1-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T23:05:27.828026Z",
     "start_time": "2025-01-11T23:05:27.781871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def eval_classifier(learner, data_train, labels_train, data_test, labels_test):\n",
    "    th, th0 = learner(data_train, labels_train)\n",
    "    score = np.mean(np.sign(th.T @ data_test + th0.T) == labels_test, axis=1, keepdims=True)\n",
    "    return score.item()\n",
    "\n",
    "helper.test_eval_classifier(eval_classifier, perceptron)"
   ],
   "id": "b9211c90e9f9ae0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Eval Classifier 0-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Eval Classifier 1-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T23:05:27.945572Z",
     "start_time": "2025-01-11T23:05:27.904153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def eval_learning_alg(learner, data_gen, n_train, n_test, it):\n",
    "    total_score = 0\n",
    "    for i in range(it):\n",
    "        data_train, labels_train = data_gen(n_train)\n",
    "        data_test, labels_test = data_gen(n_test)\n",
    "\n",
    "        total_score += eval_classifier(learner, data_train, labels_train, data_test, labels_test)\n",
    "    return total_score/it\n",
    "\n",
    "helper.test_eval_learning_alg(eval_learning_alg,perceptron)"
   ],
   "id": "dd49ec90dd68ceb9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Eval Learning Algo-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T23:05:28.245860Z",
     "start_time": "2025-01-11T23:05:27.964336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from code_for_hw02_downloadable import score\n",
    "\n",
    "def xval_learning_alg(learner, data, labels, k):\n",
    "    #cross validation of learning algorithm\n",
    "    score_sum = 0\n",
    "    data_list = np.array_split(data, k, axis=1) # data   dxn\n",
    "    labels_list = np.array_split(labels, k, axis=1)   # labels 1xn\n",
    "    for i in range(k):\n",
    "        data_train = np.concatenate([part for j,part in enumerate(data_list) if j !=i], axis=1)\n",
    "        labels_train = np.concatenate([part for j,part in enumerate(labels_list) if j !=i], axis=1)\n",
    "        data_test = data_list[i]\n",
    "        labels_test = labels_list[i]\n",
    "        score_sum += eval_classifier(learner, data_train, labels_train, data_test, labels_test)\n",
    "        # th, th0 = learner(data_train, labels_train)\n",
    "        # score_sum += score(data_test, labels_test, th, th0) / data_test.shape[1]\n",
    "    return score_sum / k\n",
    "\n",
    "helper.test_xval_learning_alg(xval_learning_alg, perceptron)"
   ],
   "id": "4bceb3b7f58898d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Cross-eval Learning Algo-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T23:05:34.480514Z",
     "start_time": "2025-01-11T23:05:28.260915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for pflip in [0.1, 0.25]:\n",
    "    for alg in [perceptron, averaged_perceptron]:\n",
    "        accuracy = eval_learning_alg(alg, helper.gen_flipped_lin_separable(pflip=pflip), 20, 20,100)\n",
    "        print(pflip, alg.__name__, accuracy)"
   ],
   "id": "2b5f32d9a825dd38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 perceptron 0.7540000000000002\n",
      "0.1 averaged_perceptron 0.8095000000000002\n",
      "0.25 perceptron 0.5850000000000001\n",
      "0.25 averaged_perceptron 0.6400000000000001\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T23:05:40.517255Z",
     "start_time": "2025-01-11T23:05:34.489068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training_accuracy(learner, data_gen, n_train, it):\n",
    "    total_score = 0\n",
    "    for i in range(it):\n",
    "        data_train, labels_train = data_gen(n_train)\n",
    "        total_score += eval_classifier(learner, data_train, labels_train, data_train, labels_train)\n",
    "    return total_score/it\n",
    "\n",
    "for pflip in [0.1, 0.25]:\n",
    "    for alg in [perceptron, averaged_perceptron]:\n",
    "        accuracy = training_accuracy(alg, helper.gen_flipped_lin_separable(pflip=pflip), 20,100)\n",
    "        print(pflip, alg.__name__, accuracy)\n",
    "\n"
   ],
   "id": "906d4c9e830665dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 perceptron 0.8099999999999997\n",
      "0.1 averaged_perceptron 0.8660000000000003\n",
      "0.25 perceptron 0.6679999999999998\n",
      "0.25 averaged_perceptron 0.7150000000000002\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
